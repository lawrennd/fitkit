{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/lawrennd/fitkit/blob/main/examples/nested_matrix_fitness_complexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Matrix: Fitness / Complexity Analysis\n",
    "\n",
    "This notebook demonstrates fitness-complexity analysis on a **perfectly nested binary matrix**.\n",
    "\n",
    "**Hypothesis**: For nested data (countries with more products export all products that countries with fewer products export, plus additional ones), we expect **ECI to correlate very highly with diversification** (r > 0.9) since this is the use case ECI was designed for. We also expect **very high ECI-log(Fitness) correlation** (r > 0.9) since both metrics should capture the nested structure. Note: we use log(Fitness) because Fitness is multiplicative/exponential, while ECI and diversification are linear scales.\n",
    "\n",
    "**What is a nested matrix?** In a perfectly nested structure:\n",
    "- Row i includes all products from rows 0 to i-1, plus one additional product\n",
    "- This creates a triangular/hierarchical pattern\n",
    "- Common in trade data: sophisticated countries export everything simple countries export, plus more\n",
    "\n",
    "The notebook:\n",
    "- Generates a nested sparse binary matrix (users × words)\n",
    "- Applies Fitness-Complexity, ECI, and Sinkhorn scaling\n",
    "- Visualizes the correlation between ECI and Fitness\n",
    "- Compares convergence and diagnostic plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Install fitkit if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _pip_install(args: list[str]) -> None:\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", *args]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "\n",
    "def ensure_fitkit_installed() -> None:\n",
    "    \"\"\"Prefer editable local install; fall back to GitHub.\n",
    "\n",
    "    - Local (typical): `pip install -e ..` when running from `examples/`\n",
    "    - Colab/remote: `pip install git+https://github.com/lawrennd/fitkit.git`\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import fitkit  # noqa: F401\n",
    "\n",
    "        return\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    here = Path.cwd().resolve()\n",
    "    candidates = [here, here.parent, here.parent.parent]\n",
    "\n",
    "    for root in candidates:\n",
    "        if (root / \"pyproject.toml\").exists() and (root / \"fitkit\").is_dir():\n",
    "            _pip_install([\"install\", \"-e\", str(root)])\n",
    "            return\n",
    "\n",
    "    _pip_install([\"install\", \"git+https://github.com/lawrennd/fitkit.git\"])\n",
    "\n",
    "\n",
    "ensure_fitkit_installed()\n",
    "import fitkit\n",
    "\n",
    "print(\"fitkit version:\", getattr(fitkit, \"__version__\", \"unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitkit.algorithms import FitnessComplexity, ECI, SinkhornScaler\n",
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sparse matrices\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Nested Binary Matrix\n",
    "\n",
    "We create a perfectly nested sparse binary matrix representing a user × word incidence matrix.\n",
    "- `n_users`: number of users (rows)\n",
    "- `n_words`: number of words (columns)\n",
    "- Each user i uses words 0 through (i + base_words), creating perfect nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility (for any randomness in ordering)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Matrix parameters\n",
    "n_users = 200\n",
    "n_words = 300  # More words than users to create interesting structure\n",
    "base_words = 5  # Minimum words per user\n",
    "\n",
    "# Generate perfectly nested matrix\n",
    "# User i uses words 0 through min(i + base_words, n_words)\n",
    "# Note: Words beyond (n_users + base_words - 1) will be unused (isolated)\n",
    "M_data = []\n",
    "for i in range(n_users):\n",
    "    row = np.zeros(n_words)\n",
    "    # Each user includes all previous users' words, plus one more\n",
    "    n_words_for_user = min(i + base_words, n_words)\n",
    "    row[:n_words_for_user] = 1\n",
    "    M_data.append(row)\n",
    "\n",
    "M = sp.csr_matrix(np.array(M_data))\n",
    "\n",
    "# Create labels\n",
    "user_ids = [f\"user_{i:03d}\" for i in range(n_users)]\n",
    "vocab = [f\"word_{i:03d}\" for i in range(n_words)]\n",
    "\n",
    "n_words_used = min(n_users + base_words - 1, n_words)\n",
    "n_words_isolated = n_words - n_words_used\n",
    "\n",
    "print(f\"Generated nested matrix: {n_users} users × {n_words} words\")\n",
    "print(f\"Matrix shape: {M.shape}, dtype: {M.dtype}\")\n",
    "print(f\"Density: {M.nnz / (M.shape[0] * M.shape[1]):.2%}\")\n",
    "print(f\"Total non-zero entries: {M.nnz}\")\n",
    "print(f\"Diversification range: [{M.sum(axis=1).min():.0f}, {M.sum(axis=1).max():.0f}]\")\n",
    "print(f\"Ubiquity range: [{M.sum(axis=0).min():.0f}, {M.sum(axis=0).max():.0f}]\")\n",
    "print(f\"Words used: {n_words_used}/{n_words} (isolated: {n_words_isolated})\")\n",
    "if n_words_isolated > 0:\n",
    "    print(f\"Note: {n_words_isolated} words will have NaN values in ECI output (expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic margins (diversification and ubiquity)\n",
    "user_strength = np.asarray(M.sum(axis=1)).ravel()\n",
    "word_strength = np.asarray(M.sum(axis=0)).ravel()\n",
    "\n",
    "print(\"User diversification (# words per user):\")\n",
    "print(pd.Series(user_strength).describe())\n",
    "print(\"\\nWord ubiquity (# users per word):\")\n",
    "print(pd.Series(word_strength).describe())\n",
    "\n",
    "# Create labeled DataFrame\n",
    "M_df = pd.DataFrame.sparse.from_spmatrix(M, index=user_ids, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Algorithms\n",
    "\n",
    "We compute:\n",
    "1. **Fitness-Complexity** (FC): Nonlinear rank-1 fixed point\n",
    "2. **ECI/PCI**: Economic Complexity Index via eigenvalue decomposition\n",
    "3. **Sinkhorn scaling**: IPF/OT coupling on the support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fitness-Complexity\n",
    "fc = FitnessComplexity()\n",
    "F, Q = fc.fit_transform(M)\n",
    "fc_hist = fc.history_\n",
    "\n",
    "# 2) ECI\n",
    "eci_model = ECI()\n",
    "eci, pci = eci_model.fit_transform(M)\n",
    "\n",
    "# Create series\n",
    "F_s = pd.Series(F, index=user_ids, name=\"Fitness\")\n",
    "Q_s = pd.Series(Q, index=vocab, name=\"Complexity\")\n",
    "eci_s = pd.Series(eci, index=user_ids, name=\"ECI\")\n",
    "pci_s = pd.Series(pci, index=vocab, name=\"PCI\")\n",
    "\n",
    "kc = pd.Series(np.asarray(M.sum(axis=1)).ravel(), index=user_ids, name=\"diversification_kc\")\n",
    "kp = pd.Series(np.asarray(M.sum(axis=0)).ravel(), index=vocab, name=\"ubiquity_kp\")\n",
    "\n",
    "# 3) Sinkhorn scaling with uniform marginals\n",
    "r_uniform = np.ones(M.shape[0], dtype=float)\n",
    "r_uniform = r_uniform / r_uniform.sum()\n",
    "c_uniform = np.ones(M.shape[1], dtype=float)\n",
    "c_uniform = c_uniform / c_uniform.sum()\n",
    "\n",
    "scaler = SinkhornScaler()\n",
    "W = scaler.fit_transform(M, row_marginals=r_uniform, col_marginals=c_uniform)\n",
    "u, v, sk_hist = scaler.u_, scaler.v_, scaler.history_\n",
    "\n",
    "if not sk_hist.get(\"converged\", False):\n",
    "    print(\"Sinkhorn with uniform marginals did not converge; falling back to degree marginals.\")\n",
    "    r_deg = kc.to_numpy(dtype=float)\n",
    "    r_deg = r_deg / r_deg.sum()\n",
    "    c_deg = kp.to_numpy(dtype=float)\n",
    "    c_deg = c_deg / c_deg.sum()\n",
    "    scaler = SinkhornScaler()\n",
    "    W = scaler.fit_transform(M, row_marginals=r_deg, col_marginals=c_deg)\n",
    "    u, v, sk_hist = scaler.u_, scaler.v_, scaler.history_\n",
    "\n",
    "# Combine results\n",
    "results_users = pd.concat([F_s, eci_s, kc], axis=1).sort_values(\"Fitness\", ascending=False)\n",
    "results_words = pd.concat([Q_s, pci_s, kp], axis=1).sort_values(\"Complexity\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 users by Fitness:\")\n",
    "print(results_users.head(10))\n",
    "print(\"\\nTop 10 words by Complexity:\")\n",
    "print(results_words.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# Fitness-Complexity convergence\n",
    "ax[0].plot(fc.history_[\"dF\"], label=\"max |ΔF|\")\n",
    "ax[0].plot(fc.history_[\"dQ\"], label=\"max |ΔQ|\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[0].set_ylabel(\"Change\")\n",
    "ax[0].set_title(\"Fitness-Complexity Convergence\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sinkhorn convergence\n",
    "ax[1].plot(scaler.history_[\"dr\"], label=\"max row marginal error\")\n",
    "ax[1].plot(scaler.history_[\"dc\"], label=\"max col marginal error\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_xlabel(\"Iteration\")\n",
    "ax[1].set_ylabel(\"Error\")\n",
    "ax[1].set_title(\"Sinkhorn/IPF Convergence\")\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness vs ECI Correlation\n",
    "\n",
    "**Key result**: For nested matrices, we expect:\n",
    "- **Very high correlation** between ECI and diversification (r > 0.9) - this is ECI's design use case\n",
    "- **Very high correlation** between ECI and log(Fitness) (r > 0.9) - both capture nested structure\n",
    "- ECI should work excellently on this structured data\n",
    "\n",
    "**Note**: We use log(Fitness) for correlation because Fitness is a multiplicative/exponential quantity, while ECI and diversification are on linear scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log(Fitness) for meaningful correlation with linear scales\n",
    "results_users[\"log_Fitness\"] = np.log(results_users[\"Fitness\"])\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_logF = results_users[\"log_Fitness\"].corr(results_users[\"ECI\"])\n",
    "correlation_raw = results_users[\"Fitness\"].corr(results_users[\"ECI\"])\n",
    "print(f\"Pearson correlation between log(Fitness) and ECI: {correlation_logF:.4f}\")\n",
    "print(f\"Pearson correlation between Fitness and ECI (raw): {correlation_raw:.4f}\")\n",
    "\n",
    "# Scatter plot with log(Fitness)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(results_users[\"ECI\"], results_users[\"log_Fitness\"], \n",
    "            s=30, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "plt.xlabel(\"ECI (standardised)\", fontsize=12)\n",
    "plt.ylabel(\"log(Fitness)\", fontsize=12)\n",
    "plt.title(f\"Nested Matrix: log(Fitness) vs ECI\\n(Correlation: {correlation_logF:.4f})\", fontsize=13)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Original Fitness on log scale (for comparison)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(results_users[\"ECI\"], results_users[\"Fitness\"], \n",
    "            s=30, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "plt.xlabel(\"ECI (standardised)\", fontsize=12)\n",
    "plt.ylabel(\"Fitness (log scale)\", fontsize=12)\n",
    "plt.title(f\"Nested Matrix: Fitness vs ECI (log scale)\\n(Note: correlation computed on log(Fitness): {correlation_logF:.4f})\", fontsize=13)\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Structure Visualization\n",
    "\n",
    "Visualize the binary matrix sorted by Fitness (rows) and Complexity (columns). For random data, we don't expect to see clear nested or modular patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort matrix by Fitness and Complexity\n",
    "M_sorted = M_df.loc[results_users.index, results_words.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(M_sorted.sparse.to_dense().to_numpy(), \n",
    "           aspect=\"auto\", interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.colorbar(label=\"Presence (binary)\")\n",
    "plt.title(\"Nested Matrix sorted by Fitness (rows) and Complexity (cols)\\nNote the triangular (nested) pattern\")\n",
    "plt.xlabel(\"Words (sorted by Complexity)\")\n",
    "plt.ylabel(\"Users (sorted by Fitness)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Fitness distribution\n",
    "axes[0, 0].hist(F, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel(\"Fitness\")\n",
    "axes[0, 0].set_ylabel(\"Count\")\n",
    "axes[0, 0].set_title(\"Fitness Distribution\")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ECI distribution\n",
    "axes[0, 1].hist(eci, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_xlabel(\"ECI\")\n",
    "axes[0, 1].set_ylabel(\"Count\")\n",
    "axes[0, 1].set_title(\"ECI Distribution\")\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Complexity distribution\n",
    "axes[1, 0].hist(Q, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].set_xlabel(\"Complexity\")\n",
    "axes[1, 0].set_ylabel(\"Count\")\n",
    "axes[1, 0].set_title(\"Complexity Distribution\")\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# PCI distribution\n",
    "axes[1, 1].hist(pci, bins=30, edgecolor='black', alpha=0.7, color='red')\n",
    "axes[1, 1].set_xlabel(\"PCI\")\n",
    "axes[1, 1].set_ylabel(\"Count\")\n",
    "axes[1, 1].set_title(\"PCI Distribution\")\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Diversification\n",
    "\n",
    "Compare Fitness and ECI with simple diversification (number of words per user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fitness vs Diversification\n",
    "axes[0].scatter(results_users[\"diversification_kc\"], results_users[\"Fitness\"],\n",
    "                s=30, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "axes[0].set_xlabel(\"Diversification (# words)\")\n",
    "axes[0].set_ylabel(\"Fitness\")\n",
    "axes[0].set_title(\"Fitness vs Diversification\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ECI vs Diversification\n",
    "axes[1].scatter(results_users[\"diversification_kc\"], results_users[\"ECI\"],\n",
    "                s=30, alpha=0.6, edgecolors='k', linewidths=0.5, color='orange')\n",
    "axes[1].set_xlabel(\"Diversification (# words)\")\n",
    "axes[1].set_ylabel(\"ECI\")\n",
    "axes[1].set_title(\"ECI vs Diversification\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMatrix size: {n_users} users × {n_words} words\")\n",
    "print(f\"Matrix type: perfectly nested\")\n",
    "print(f\"Density: {M.nnz / (M.shape[0] * M.shape[1]):.2%}\")\n",
    "print(f\"\\nFitness-Complexity converged: {fc_hist.get('converged', False)}\")\n",
    "print(f\"FC iterations: {len(fc_hist['dF'])}\")\n",
    "print(f\"\\nSinkhorn converged: {sk_hist.get('converged', False)}\")\n",
    "print(f\"Sinkhorn iterations: {len(sk_hist['dr'])}\")\n",
    "print(f\"\\n{'Correlation between ECI and Diversification:':<45} {results_users['ECI'].corr(results_users['diversification_kc']):.4f}\")\n",
    "print(f\"{'Correlation between log(Fitness) and Diversification:':<45} {results_users['log_Fitness'].corr(results_users['diversification_kc']):.4f}\")\n",
    "print(f\"{'Correlation between log(Fitness) and ECI:':<45} {correlation_logF:.4f}\")\n",
    "print(f\"{'Correlation between log(Complexity) and PCI:':<45} {np.log(results_words['Complexity']).corr(results_words['PCI']):.4f}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"For NESTED matrices (ECI's design use case):\")\n",
    "print(\"- ECI ↔ Diversification should be VERY HIGH (r > 0.9) ✓\")\n",
    "print(\"- log(Fitness) ↔ ECI should be VERY HIGH (r > 0.9) ✓\")\n",
    "print(\"- Both metrics capture the nested structure excellently!\")\n",
    "print(\"- Note: log(Fitness) used for meaningful comparison (Fitness is multiplicative)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Structure Sensitivity\n",
    "\n",
    "**Key Question**: How sensitive is ECI to deviations from perfect nesting?\n",
    "\n",
    "Real-world data often has **multiple specialist communities** (e.g., different fields in Wikipedia) rather than a single nested hierarchy. Let's test how this affects ECI vs Fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test matrices with increasing number of communities\n",
    "n_communities_list = [1, 2, 3, 5]\n",
    "results_by_communities = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ECI SENSITIVITY TO COMMUNITY STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCreating matrices with multiple specialist communities...\\n\")\n",
    "print(f\"{'Communities':<15} {'ECI↔Div':<12} {'log(F)↔Div':<12} {'Degradation':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for n_communities in n_communities_list:\n",
    "    # Create matrix with n communities\n",
    "    M_comm_data = []\n",
    "    rows_per_community = n_users // n_communities\n",
    "    cols_per_community = n_words // n_communities\n",
    "    \n",
    "    for comm_idx in range(n_communities):\n",
    "        # Each community has nested structure within itself\n",
    "        for i in range(rows_per_community):\n",
    "            row = np.zeros(n_words)\n",
    "            # Common words (first 20% of columns)\n",
    "            n_common = int(0.2 * n_words)\n",
    "            row[:n_common] = (np.random.rand(n_common) > 0.3).astype(float)\n",
    "            \n",
    "            # Community-specific words (nested within community)\n",
    "            comm_start = n_common + comm_idx * (cols_per_community - n_common // n_communities)\n",
    "            comm_end = min(comm_start + int((i + 1) * 0.7 * cols_per_community / rows_per_community), n_words)\n",
    "            if comm_start < n_words:\n",
    "                row[comm_start:comm_end] = 1\n",
    "            \n",
    "            M_comm_data.append(row)\n",
    "    \n",
    "    M_comm = sp.csr_matrix(np.array(M_comm_data))\n",
    "    \n",
    "    # Compute ECI and Fitness\n",
    "    eci_comm, _ = compute_eci_pci(M_comm)\n",
    "    F_comm, Q_comm, _ = fitness_complexity(M_comm)\n",
    "    \n",
    "    # Compute correlations\n",
    "    div_comm = np.asarray(M_comm.sum(axis=1)).ravel()\n",
    "    log_F_comm = np.log(F_comm)\n",
    "    \n",
    "    corr_eci_comm = np.corrcoef(eci_comm, div_comm)[0, 1]\n",
    "    corr_logF_comm = np.corrcoef(log_F_comm, div_comm)[0, 1]\n",
    "    \n",
    "    results_by_communities.append({\n",
    "        'n_communities': n_communities,\n",
    "        'eci_corr': corr_eci_comm,\n",
    "        'logF_corr': corr_logF_comm\n",
    "    })\n",
    "    \n",
    "    if n_communities == 1:\n",
    "        degradation = \"(baseline)\"\n",
    "    else:\n",
    "        deg_eci = results_by_communities[0]['eci_corr'] - corr_eci_comm\n",
    "        degradation = f\"ECI: {deg_eci:+.3f}\"\n",
    "    \n",
    "    print(f\"{n_communities:<15} {corr_eci_comm:>6.3f}       {corr_logF_comm:>6.3f}       {degradation:<15}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n⚠️  KEY FINDING: Community/modular structure DESTROYS ECI!\")\n",
    "print(f\"\\n  • 1 community (nested):      ECI={results_by_communities[0]['eci_corr']:.3f}\")\n",
    "print(f\"  • 2 communities:             ECI={results_by_communities[1]['eci_corr']:.3f} (drops {results_by_communities[0]['eci_corr'] - results_by_communities[1]['eci_corr']:.3f})\")\n",
    "print(f\"  • {n_communities_list[-1]} communities:            ECI={results_by_communities[-1]['eci_corr']:.3f} (essentially noise!)\")\n",
    "print(f\"\\n  • log(Fitness) much more robust: {results_by_communities[0]['logF_corr']:.3f} → {results_by_communities[-1]['logF_corr']:.3f}\")\n",
    "print(\"\\nThis explains Wikipedia data: multiple specialist communities\")\n",
    "print(\"(astrophysics, biology, history) each with specialized vocabulary.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the degradation\n",
    "n_comms = [r['n_communities'] for r in results_by_communities]\n",
    "eci_corrs = [r['eci_corr'] for r in results_by_communities]\n",
    "logF_corrs = [r['logF_corr'] for r in results_by_communities]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_comms, eci_corrs, 'o-', linewidth=2, markersize=8, label='ECI ↔ Diversification')\n",
    "plt.plot(n_comms, logF_corrs, 's-', linewidth=2, markersize=8, label='log(Fitness) ↔ Diversification')\n",
    "plt.axhline(0.7, color='red', linestyle='--', alpha=0.5, label='Threshold (0.7)')\n",
    "plt.xlabel('Number of Communities', fontsize=12)\n",
    "plt.ylabel('Correlation with Diversification', fontsize=12)\n",
    "plt.title('ECI vs Fitness: Sensitivity to Community Structure', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ ECI works perfectly on single nested hierarchy\")\n",
    "print(\"✗ ECI breaks down with just 2 communities\")\n",
    "print(\"✓ log(Fitness) remains meaningful across all structures\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
