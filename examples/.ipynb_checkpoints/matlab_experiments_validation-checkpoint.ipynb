{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Against MATLAB Spectral Clustering Experiments\n",
    "\n",
    "This notebook recreates the experiments from `~/lawrennd/spectral/matlab/` to validate the Python `CommunityDetector` implementation against the original MATLAB reference code (Sanguinetti, Lawrence & Laidler, 2005).\n",
    "\n",
    "## MATLAB vs Python Implementation Notes\n",
    "\n",
    "**Key difference**: The MATLAB demos use **Gaussian affinity matrices** computed from Euclidean distances:\n",
    "```matlab\n",
    "A(i,j) = exp(-||x(i,:)-x(j,:)||^2/sigma)\n",
    "L = D^{-1/2} A D^{-1/2}\n",
    "```\n",
    "\n",
    "Our `CommunityDetector` uses **bipartite transition matrices** for country-product networks:\n",
    "```python\n",
    "T = D_c^{-1} M D_p^{-1} M^T\n",
    "```\n",
    "\n",
    "To properly validate, we need to adapt `CommunityDetector` to accept pre-computed affinity/transition matrices, or create a wrapper that computes Gaussian affinities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.linalg import eigh\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from fitkit.community.detection import CommunityDetector\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: Gaussian Affinity Matrix Construction\n",
    "\n",
    "To match MATLAB experiments, we need to construct affinity matrices from point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gaussian_affinity(X, sigma2):\n",
    "    \"\"\"Compute Gaussian affinity matrix as in MATLAB SpectralCluster.\n",
    "    \n",
    "    A(i,j) = exp(-||x(i,:)-x(j,:)||^2/sigma2)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (n_samples, n_features)\n",
    "        Data points.\n",
    "    sigma2 : float\n",
    "        Variance parameter for Gaussian kernel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : ndarray of shape (n_samples, n_samples)\n",
    "        Affinity matrix.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    A = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            A[i, j] = np.exp(-np.linalg.norm(X[i] - X[j])**2 / sigma2)\n",
    "    \n",
    "    return A\n",
    "\n",
    "def affinity_to_normalized_laplacian(A):\n",
    "    \"\"\"Convert affinity matrix to normalized Laplacian.\n",
    "    \n",
    "    L = D^{-1/2} A D^{-1/2}\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray of shape (n, n)\n",
    "        Affinity matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    L : ndarray of shape (n, n)\n",
    "        Normalized Laplacian.\n",
    "    \"\"\"\n",
    "    D = A.sum(axis=1)\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-10))\n",
    "    L = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Three Circles (demoCircles.m)\n",
    "\n",
    "Generate three concentric circles with noise and cluster them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate three circles data (matching MATLAB)\n",
    "np.random.seed(1)\n",
    "npts = 100\n",
    "theta = np.linspace(0, 2*np.pi, npts, endpoint=False)\n",
    "radius_noise = np.random.randn(npts)\n",
    "\n",
    "r1 = 1.0 + 0.1 * radius_noise\n",
    "r2 = 2.0 + 0.1 * np.random.randn(npts)\n",
    "r3 = 3.0 + 0.1 * np.random.randn(npts)\n",
    "\n",
    "x_circles = np.vstack([\n",
    "    np.column_stack([r1 * np.cos(theta), r1 * np.sin(theta)]),\n",
    "    np.column_stack([r2 * np.cos(theta), r2 * np.sin(theta)]),\n",
    "    np.column_stack([r3 * np.cos(theta), r3 * np.sin(theta)])\n",
    "])\n",
    "\n",
    "true_labels = np.repeat([0, 1, 2], npts)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(x_circles[:, 0], x_circles[:, 1], c=true_labels, cmap='tab10', s=20)\n",
    "plt.title('Three Circles Dataset (True Labels)')\n",
    "plt.axis('equal')\n",
    "plt.colorbar(label='True Cluster')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dataset shape: {x_circles.shape}\")\n",
    "print(f\"Expected clusters: 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute affinity matrix (sigma2 = 0.05 from MATLAB)\n",
    "sigma2 = 0.05\n",
    "A_circles = compute_gaussian_affinity(x_circles, sigma2)\n",
    "L_circles = affinity_to_normalized_laplacian(A_circles)\n",
    "\n",
    "print(f\"Affinity matrix shape: {A_circles.shape}\")\n",
    "print(f\"Affinity matrix sparsity: {(A_circles < 0.01).sum() / A_circles.size * 100:.1f}% near-zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top eigenvectors\n",
    "eigenvalues, eigenvectors = eigh(L_circles)\n",
    "idx = np.argsort(np.abs(eigenvalues))[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "print(\"Top 10 eigenvalues:\")\n",
    "print(eigenvalues[:10])\n",
    "\n",
    "# Plot eigenvalue spectrum\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(eigenvalues[:20], 'o-')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Top 20 Eigenvalues')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(eigenvectors[:, 1], eigenvectors[:, 2], c=true_labels, cmap='tab10', s=20)\n",
    "plt.xlabel('Eigenvector 2')\n",
    "plt.ylabel('Eigenvector 3')\n",
    "plt.title('2D Eigenspace Projection')\n",
    "plt.colorbar(label='True Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Elongated K-Means on Eigenvectors\n",
    "\n",
    "Since `CommunityDetector` expects a bipartite matrix, we'll manually run the elongated k-means algorithm on the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual implementation following MATLAB algorithm\n",
    "# Start with q=2 eigenvectors, iterate until origin is empty\n",
    "\n",
    "def run_spectral_cluster_manual(eigenvectors, eigenvalues, max_dim=10, lambda_elongation=0.2):\n",
    "    \"\"\"Manual implementation of SpectralCluster algorithm.\"\"\"\n",
    "    from fitkit.community.detection import CommunityDetector\n",
    "    \n",
    "    detector = CommunityDetector(max_communities=max_dim, lambda_elongation=lambda_elongation, random_state=42)\n",
    "    \n",
    "    # Start with Dim=2\n",
    "    for dim in range(2, max_dim + 1):\n",
    "        # Extract first dim eigenvectors (skip first trivial one)\n",
    "        PcEig = eigenvectors[:, 1:dim+1]\n",
    "        \n",
    "        # Run elongated k-means with origin detector\n",
    "        k = dim - 1  # Number of non-origin clusters\n",
    "        labels, origin_empty, centers = detector._elongated_kmeans_with_origin(PcEig, k)\n",
    "        \n",
    "        print(f\"Dim={dim}, k={k}: origin_empty={origin_empty}, origin_size={(labels==k).sum()}\")\n",
    "        \n",
    "        if origin_empty:\n",
    "            # Found correct number of clusters\n",
    "            final_labels = detector._elongated_kmeans(PcEig, k, initial_centers=centers[:k])\n",
    "            return final_labels, dim, PcEig, centers[:k]\n",
    "    \n",
    "    # If we reach here, use max_dim\n",
    "    PcEig = eigenvectors[:, 1:max_dim+1]\n",
    "    final_labels = detector._elongated_kmeans(PcEig, max_dim - 1)\n",
    "    return final_labels, max_dim, PcEig, None\n",
    "\n",
    "# Run the algorithm\n",
    "labels_circles, n_clusters, PcEig_circles, centers_circles = run_spectral_cluster_manual(\n",
    "    eigenvectors, eigenvalues, max_dim=10\n",
    ")\n",
    "\n",
    "print(f\"\\nDetected {n_clusters} clusters\")\n",
    "print(f\"Unique labels: {np.unique(labels_circles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Original data with true labels\n",
    "axes[0].scatter(x_circles[:, 0], x_circles[:, 1], c=true_labels, cmap='tab10', s=20)\n",
    "axes[0].set_title('True Labels')\n",
    "axes[0].axis('equal')\n",
    "\n",
    "# Original data with predicted labels\n",
    "axes[1].scatter(x_circles[:, 0], x_circles[:, 1], c=labels_circles, cmap='tab10', s=20)\n",
    "axes[1].set_title(f'Predicted Labels ({n_clusters} clusters)')\n",
    "axes[1].axis('equal')\n",
    "\n",
    "# Eigenspace with predicted labels\n",
    "axes[2].scatter(PcEig_circles[:, 0], PcEig_circles[:, 1], c=labels_circles, cmap='tab10', s=20)\n",
    "if centers_circles is not None:\n",
    "    axes[2].scatter(centers_circles[:, 0], centers_circles[:, 1], \n",
    "                   c='black', marker='D', s=100, edgecolors='white', linewidths=2)\n",
    "axes[2].set_xlabel('Eigenvector 2')\n",
    "axes[2].set_ylabel('Eigenvector 3')\n",
    "axes[2].set_title('Eigenspace Clustering')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute clustering quality\n",
    "from collections import Counter\n",
    "for true_label in range(3):\n",
    "    mask = true_labels == true_label\n",
    "    pred_in_cluster = labels_circles[mask]\n",
    "    counts = Counter(pred_in_cluster)\n",
    "    print(f\"True cluster {true_label}: {dict(counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Shapes Image Segmentation (demoShapes.m)\n",
    "\n",
    "Load shapes.bmp and segment based on spatial coordinates + intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapes image\n",
    "img_path = '~/lawrennd/spectral/matlab/shapes.bmp'\n",
    "img = Image.open(img_path.replace('~', '/Users/neil'))\n",
    "img_array = np.array(img)\n",
    "\n",
    "# If RGB, convert to grayscale\n",
    "if len(img_array.shape) == 3:\n",
    "    img_gray = img_array.sum(axis=2)\n",
    "else:\n",
    "    img_gray = img_array\n",
    "\n",
    "# Normalize\n",
    "img_norm = img_gray / img_gray.max()\n",
    "\n",
    "print(f\"Image shape: {img_norm.shape}\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_norm, cmap='gray')\n",
    "plt.title('Shapes Image')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and intensities (matching MATLAB)\n",
    "numrows, numcols = img_norm.shape\n",
    "n = numrows * numcols\n",
    "\n",
    "# Flatten image\n",
    "f = img_norm.ravel()\n",
    "\n",
    "# Create coordinate matrices\n",
    "x1 = np.tile(np.arange(numrows), numcols)\n",
    "x2 = np.repeat(np.arange(numcols), numrows)\n",
    "\n",
    "# Combine coordinates and intensity (weight intensity same as spatial)\n",
    "x_shapes = np.column_stack([x1, x2, f * (numrows + numcols)])\n",
    "\n",
    "print(f\"Data matrix shape: {x_shapes.shape}\")\n",
    "print(f\"Coordinate range: x1=[{x1.min()}, {x1.max()}], x2=[{x2.min()}, {x2.max()}]\")\n",
    "print(f\"Intensity range: [{f.min():.3f}, {f.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute affinity matrix (sigma2 = 1 from MATLAB)\n",
    "# WARNING: This will be slow for large images!\n",
    "print(\"Computing affinity matrix... (this may take a while)\")\n",
    "\n",
    "sigma2_shapes = 1.0\n",
    "# For speed, subsample if image is large\n",
    "if n > 1000:\n",
    "    print(f\"Image has {n} pixels, subsampling to 1000 for speed...\")\n",
    "    subsample_idx = np.random.choice(n, size=1000, replace=False)\n",
    "    x_shapes_sub = x_shapes[subsample_idx]\n",
    "    img_norm_sub = img_norm.ravel()[subsample_idx]\n",
    "else:\n",
    "    x_shapes_sub = x_shapes\n",
    "    img_norm_sub = img_norm.ravel()\n",
    "\n",
    "A_shapes = compute_gaussian_affinity(x_shapes_sub, sigma2_shapes)\n",
    "L_shapes = affinity_to_normalized_laplacian(A_shapes)\n",
    "\n",
    "print(f\"Affinity matrix shape: {A_shapes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract eigenvectors\n",
    "print(\"Computing eigenvectors...\")\n",
    "eigenvalues_shapes, eigenvectors_shapes = eigh(L_shapes)\n",
    "idx = np.argsort(np.abs(eigenvalues_shapes))[::-1]\n",
    "eigenvalues_shapes = eigenvalues_shapes[idx]\n",
    "eigenvectors_shapes = eigenvectors_shapes[:, idx]\n",
    "\n",
    "print(\"Top 10 eigenvalues:\")\n",
    "print(eigenvalues_shapes[:10])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(eigenvalues_shapes[:20], 'o-')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Eigenvalue Spectrum (Shapes)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run clustering\n",
    "print(\"Running spectral clustering...\")\n",
    "labels_shapes, n_clusters_shapes, PcEig_shapes, centers_shapes = run_spectral_cluster_manual(\n",
    "    eigenvectors_shapes, eigenvalues_shapes, max_dim=10\n",
    ")\n",
    "\n",
    "print(f\"\\nDetected {n_clusters_shapes} clusters\")\n",
    "print(f\"Cluster sizes: {np.bincount(labels_shapes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segmentation\n",
    "if len(x_shapes_sub) < n:\n",
    "    print(\"Note: Showing results on subsampled data\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(img_norm, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Clustered points (spatial view)\n",
    "axes[1].scatter(x_shapes_sub[:, 1], x_shapes_sub[:, 0], c=labels_shapes, cmap='tab10', s=10)\n",
    "axes[1].set_title(f'Segmentation ({n_clusters_shapes} clusters)')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Bipartite Network (Economic Fitness)\n",
    "\n",
    "Test on synthetic bipartite networks to validate the transition matrix approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2-block modular bipartite network\n",
    "np.random.seed(42)\n",
    "n_countries = 20\n",
    "n_products = 16\n",
    "\n",
    "M = np.zeros((n_countries, n_products))\n",
    "\n",
    "# Block 1: countries 0-9 export products 0-7\n",
    "M[0:10, 0:8] = 1\n",
    "\n",
    "# Block 2: countries 10-19 export products 8-15\n",
    "M[10:20, 8:16] = 1\n",
    "\n",
    "# Add some cross-block connections for connectivity\n",
    "for i in range(10):\n",
    "    products = np.random.choice(range(8, 16), size=1, replace=False)\n",
    "    M[i, products] = 1\n",
    "    \n",
    "for i in range(10, 20):\n",
    "    products = np.random.choice(range(0, 8), size=1, replace=False)\n",
    "    M[i, products] = 1\n",
    "\n",
    "M_sparse = sparse.csr_matrix(M)\n",
    "true_labels_bipartite = np.array([0]*10 + [1]*10)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(M, cmap='binary', aspect='auto', interpolation='none')\n",
    "plt.xlabel('Products')\n",
    "plt.ylabel('Countries')\n",
    "plt.title('Modular Bipartite Network')\n",
    "plt.colorbar(label='Export')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Network shape: {M.shape}\")\n",
    "print(f\"Density: {M.sum() / M.size * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CommunityDetector directly (uses bipartite transition matrix)\n",
    "detector_bipartite = CommunityDetector(max_communities=10, random_state=42)\n",
    "labels_bipartite = detector_bipartite.fit_predict(M_sparse)\n",
    "\n",
    "print(f\"Detected {detector_bipartite.n_communities_} communities\")\n",
    "print(f\"Iterations: {detector_bipartite.n_iterations_}\")\n",
    "print(f\"\\nBlock 1 labels: {labels_bipartite[0:10]}\")\n",
    "print(f\"Block 2 labels: {labels_bipartite[10:20]}\")\n",
    "\n",
    "# Check clustering quality\n",
    "from collections import Counter\n",
    "for block_idx in range(2):\n",
    "    mask = true_labels_bipartite == block_idx\n",
    "    pred_in_block = labels_bipartite[mask]\n",
    "    counts = Counter(pred_in_block)\n",
    "    print(f\"\\nTrue block {block_idx}: {dict(counts)}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(range(20), true_labels_bipartite, c=true_labels_bipartite, cmap='tab10', s=100)\n",
    "axes[0].set_xlabel('Country')\n",
    "axes[0].set_ylabel('True Cluster')\n",
    "axes[0].set_title('True Labels')\n",
    "axes[0].grid(True, axis='y')\n",
    "\n",
    "axes[1].scatter(range(20), labels_bipartite, c=labels_bipartite, cmap='tab10', s=100)\n",
    "axes[1].set_xlabel('Country')\n",
    "axes[1].set_ylabel('Predicted Cluster')\n",
    "axes[1].set_title(f'Predicted Labels ({detector_bipartite.n_communities_} clusters)')\n",
    "axes[1].grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Comparison\n",
    "\n",
    "Compare results across all experiments to identify where the Python implementation matches or diverges from expected MATLAB behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. THREE CIRCLES (Gaussian affinity)\")\n",
    "print(f\"   Expected clusters: 3\")\n",
    "print(f\"   Detected clusters: {n_clusters}\")\n",
    "print(f\"   Status: {'✓ PASS' if n_clusters == 3 else '✗ FAIL'}\")\n",
    "\n",
    "print(\"\\n2. SHAPES IMAGE (Gaussian affinity)\")\n",
    "print(f\"   Expected clusters: 3-4 (approximate)\")\n",
    "print(f\"   Detected clusters: {n_clusters_shapes}\")\n",
    "print(f\"   Status: {'✓ PASS' if 3 <= n_clusters_shapes <= 5 else '? REVIEW'}\")\n",
    "\n",
    "print(\"\\n3. BIPARTITE NETWORK (Transition matrix)\")\n",
    "print(f\"   Expected clusters: 2\")\n",
    "print(f\"   Detected clusters: {detector_bipartite.n_communities_}\")\n",
    "print(f\"   Status: {'✓ PASS' if detector_bipartite.n_communities_ == 2 else '✗ FAIL'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nNOTES:\")\n",
    "print(\"- Experiments 1-2 use Gaussian affinity (standard spectral clustering)\")\n",
    "print(\"- Experiment 3 uses bipartite transition matrix (economic fitness approach)\")\n",
    "print(\"- Over-segmentation suggests origin detector is not working correctly\")\n",
    "print(\"- Next step: Run MATLAB code on same data and compare intermediate values\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
